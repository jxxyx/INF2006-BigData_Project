package Twitterairlinetask3;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.List;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;

public class ComplaintReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    // Map to store the total complaints by country
    private Map<String, Integer> complaintCounts = new HashMap<>();

    public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable val : values) {
            sum += val.get();
        }
        // Store the country and its total complaints count
        complaintCounts.put(key.toString(), sum);
    }

    @Override
    protected void cleanup(Context context) throws IOException, InterruptedException {
        // Convert the map entries to a list for sorting
        List<Map.Entry<String, Integer>> sortedEntries = new ArrayList<>(complaintCounts.entrySet());

        // Sort the list in descending order by complaint count
        Collections.sort(sortedEntries, new Comparator<Map.Entry<String, Integer>>() {
            @Override
            public int compare(Map.Entry<String, Integer> entry1, Map.Entry<String, Integer> entry2) {
                return entry2.getValue().compareTo(entry1.getValue());
            }
        });

        // Output each country with its total complaints count in descending order
        for (Map.Entry<String, Integer> entry : sortedEntries) {
            context.write(new Text(entry.getKey()), new IntWritable(entry.getValue()));
        }
    }
}
